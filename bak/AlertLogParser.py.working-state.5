#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import re

# ========================= CONFIG =========================
LOG_DIR = os.path.expanduser(
    "~/Library/Application Support/net.metaquotes.wine.metatrader4/drive_c/Program Files (x86)/MetaTrader 4/MQL4/Logs"
)
SIGNAL_FILE = os.path.expanduser(
    "~/Library/Application Support/net.metaquotes.wine.metatrader4/drive_c/Program Files (x86)/MetaTrader 4/MQL4/Files/signal.txt"
)
STALE_SECONDS = 60 * 15
RISK = 0.5  # default risk percent

# ========================= STATE =========================
last_ts_per_symbol = {}
signal_queue = {}

# ========================= REGEX =========================
CLASSIC_ALERT_RE = re.compile(
    r"Alert: (\w+) [A-Z0-9]+ Entry point [0-9.]+ \((BUY|SELL)\)"
)
ALL_TF_ALERT_RE = re.compile(
    r"Alert: (\w+) All timeframes are (BUY|SELL)"
)

# ========================= HELPERS =========================
def atomic_write(path, lines):
    tmp_path = path + ".tmp"
    with open(tmp_path, "w", encoding="utf-8") as f:
        for line in lines:
            f.write(line + "\n")
    os.replace(tmp_path, path)
    print(f"[WRITE] {len(lines)} signal(s) written to {path}")


def process_alert(symbol, direction, rr=1.0):
    global last_ts_per_symbol
    ts = int(time.time())

    # Prevent duplicates/stale
    last_ts = last_ts_per_symbol.get(symbol, 0)
    if ts - last_ts < 1:
        print(f"[SKIP] Duplicate/stale alert for {symbol} ({direction})")
        return

    last_ts_per_symbol[symbol] = ts
    comment = f"MT4_ALERT|RR:{rr}"
    line = f"{symbol},{direction},{RISK},{comment},{ts}"
    signal_queue[symbol] = line
    print(f"[QUEUE] Signal queued: {line}")


# ========================= MAIN LOOP =========================
def main():
    print("Starting MT4 Alert Log Parser...")

    # Find latest log file
    files = [f for f in os.listdir(LOG_DIR) if f.lower().endswith(".log")]
    if not files:
        print("[ERROR] No log files found in", LOG_DIR)
        return
    files.sort()
    latest_log = os.path.join(LOG_DIR, files[-1])
    print("[INFO] Using log:", latest_log)

    # Track read position
    last_size = 0
    while True:
        try:
            if not os.path.exists(latest_log):
                time.sleep(1)
                continue
            size = os.path.getsize(latest_log)
            if size < last_size:
                # log rotated
                last_size = 0
            if size == last_size:
                time.sleep(0.5)
                continue

            with open(latest_log, "r", encoding="utf-8") as f:
                f.seek(last_size)
                lines = f.readlines()
                last_size = f.tell()

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # Classic alert
                m = CLASSIC_ALERT_RE.search(line)
                if m:
                    sym, dir = m.groups()
                    process_alert(sym, dir)
                    continue

                # All timeframes alert (RR=3)
                m2 = ALL_TF_ALERT_RE.search(line)
                if m2:
                    sym, dir = m2.groups()
                    process_alert(sym, dir, rr=3.0)
                    continue

            # Flush signal queue atomically
            if signal_queue:
                atomic_write(SIGNAL_FILE, list(signal_queue.values()))
                signal_queue.clear()

            time.sleep(0.2)

        except KeyboardInterrupt:
            print("Exiting parser.")
            break
        except Exception as e:
            print("[ERROR]", e)
            time.sleep(1)


if __name__ == "__main__":
    main()
